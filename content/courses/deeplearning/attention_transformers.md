---
title: Attention and Transformers
linktitle: Attention and Transformers
toc: true
type: docs
date: "2019-05-05T00:00:00+01:00"
draft: false
menu:
  example:
    parent: Main Course
    weight: 60

# Prev/next pager order (if `docs_section_pager` enabled in `params.toml`)
weight: 60
---

{{< figure library="true" src="transformer2.png" >}}

### Slides

To be uploaded after the presential lecture.

### Code

* [PyTorch: Transformer Illustration and code](https://githubtocolab.com/dlmacedo/starter-academic/blob/master/content/courses/deeplearning/notebooks/pytorch/Transformer_Illustration_and_code.ipynb)

* [PyTorch: nn.Transformer Tutorial](https://githubtocolab.com/dlmacedo/starter-academic/blob/master/content/courses/deeplearning/notebooks/pytorch/transformer_tutorial.ipynb)

* [PyTorch: Object Detection with DETR - a minimal implementation](https://githubtocolab.com/dlmacedo/starter-academic/blob/master/content/courses/deeplearning/notebooks/pytorch/detr_demo.ipynb)

### Extra

* [Jay Alammar: Visualizing machine learning one concept at a time](http://jalammar.github.io)

* [The Annotated Transformer](http://nlp.seas.harvard.edu/2018/04/03/attention.html)

* [Transformers from Scratch](http://peterbloem.nl/blog/transformers)
